# Active Graph KG - Production Hardening Guide

**Status**: SECURITY & OPS POLISH
**Priority**: P0 (JWT + Rate Limiting), P1 (Telemetry + Docs)
**Effort**: 2-3 days

---

## Executive Summary

Your reranker implementation is **correct and production-ready** ‚úÖ. The system needs **security hardening** (JWT + rate limiting) and **observability polish** (telemetry + docs) to reach enterprise-grade deployment.

**Current State:**
- ‚úÖ Reranker: dual-score design, correct skip logic, proper fallback
- ‚úÖ RLS: tenant isolation policies enabled
- ‚ùå JWT: missing (trusting client-supplied tenant_id)
- ‚ùå Rate limiting: missing (vulnerable to cost spikes, noisy neighbors)
- ‚ö†Ô∏è Telemetry: partial (missing rerank metadata in /ask responses)
- ‚ö†Ô∏è Docs: no reranker semantics documented

**Impact if deployed as-is:**
1. **Security**: Tenant isolation bypassed (client claims any tenant_id)
2. **Cost**: Unbounded LLM spend (no /ask rate limits)
3. **Reliability**: Single noisy tenant can saturate DB/LLM for all users
4. **Debuggability**: Cannot diagnose reranking decisions (no metadata)

---

## üî¥ P0: Security Hardening (JWT + Rate Limiting)

### 1. JWT Authentication (2-4 hours)

**Problem**: Your RLS implementation trusts client-supplied `tenant_id` parameters, allowing tenant impersonation.

**Files Created:**
- ‚úÖ `activekg/api/auth.py` (JWT verification middleware)
- ‚úÖ `activekg/api/rate_limiter.py` (Redis-backed rate limiter)

#### Integration Steps

**Step 1: Install dependencies**

Add to `requirements.txt`:
```txt
PyJWT[crypto]==2.8.0  # JWT verification with RS256 support
redis==5.0.1          # Rate limiting backend
```

**Step 2: Wire JWT middleware to endpoints**

Edit `activekg/api/main.py`:

```python
# Add import at top
from activekg.api.auth import get_jwt_claims, JWTClaims, require_scope
from activekg.api.rate_limiter import rate_limit_dependency, rate_limiter

# Update node creation endpoint (lines 266-285)
@app.post("/nodes")
async def create_node(
    node: Dict[str, Any],
    background_tasks: BackgroundTasks,
    claims: Optional[JWTClaims] = Depends(get_jwt_claims)  # ‚Üê Add this
):
    # Extract tenant_id from JWT instead of trusting request body
    tenant_id = claims.tenant_id if claims else node.get("tenant_id")
    actor_id = claims.actor_id if claims else "anonymous"
    actor_type = claims.actor_type if claims else "system"

    n = Node(
        classes=node.get("classes", []),
        props=node.get("props", {}),
        payload_ref=node.get("payload_ref"),
        metadata=node.get("metadata", {}),
        refresh_policy=node.get("refresh_policy", {}),
        triggers=node.get("triggers", []),
        tenant_id=tenant_id,  # ‚Üê Use JWT tenant_id, not client-supplied
    )
    node_id = repo.create_node(n)

    # Auto-embed with audit trail
    if AUTO_EMBED_ON_CREATE:
        background_tasks.add_task(_background_embed, node_id, tenant_id)

    return {"id": node_id}

# Update /ask endpoint with JWT + rate limiting (lines 671-958)
@app.post("/ask")
async def ask_question(
    request: AskRequest,
    claims: Optional[JWTClaims] = Depends(get_jwt_claims),  # ‚Üê Add JWT
    _rate_limit: None = Depends(  # ‚Üê Add rate limiting
        lambda req: rate_limit_dependency(req, "ask", claims.tenant_id if claims else None)
    )
):
    # Extract tenant context from JWT
    tenant_id = claims.tenant_id if claims else request.tenant_id
    actor_id = claims.actor_id if claims else "anonymous"

    # Mark request start for concurrency tracking
    request_id = f"{tenant_id}:{time.time()}"
    rate_limiter.mark_request_start(tenant_id, "ask", request_id)

    try:
        # ... existing /ask logic ...
        # Use tenant_id from JWT instead of request body
        results = repo.hybrid_search(
            query_text=request.question,
            query_embedding=query_embedding,
            top_k=20,
            tenant_id=tenant_id,  # ‚Üê Use JWT tenant_id
            use_reranker=not skip_rerank
        )
        # ... rest of implementation ...
    finally:
        # Mark request end for concurrency tracking
        rate_limiter.mark_request_end(tenant_id, "ask", request_id)

# Update admin endpoints with scope checks (line 1237)
@app.post("/admin/refresh", dependencies=[Depends(require_scope("admin:refresh"))])
async def admin_refresh(
    node_ids: Optional[List[str]] = None,
    claims: Optional[JWTClaims] = Depends(get_jwt_claims)
):
    # Only allow if JWT has admin:refresh scope
    ...
```

**Step 3: Environment configuration**

Add to your deployment config:

```bash
# JWT Configuration (Production)
JWT_ENABLED=true
JWT_SECRET_KEY="-----BEGIN PUBLIC KEY-----\nMIIBIjANB..."  # RS256 public key
JWT_ALGORITHM=RS256
JWT_AUDIENCE=activekg
JWT_ISSUER=https://auth.yourcompany.com

# JWT Configuration (Development - use HS256 for simplicity)
JWT_ENABLED=false  # Disable for local dev
# JWT_SECRET_KEY=your-dev-secret
# JWT_ALGORITHM=HS256

# Rate Limiting
RATE_LIMIT_ENABLED=true
REDIS_URL=redis://localhost:6379/0
```

**Step 4: Generate test JWT**

For development/testing:

```python
import jwt
from datetime import datetime, timedelta

payload = {
    "sub": "user_12345",           # actor_id
    "tenant_id": "acme_corp",      # tenant isolation
    "actor_type": "user",
    "scopes": ["search:read", "nodes:write", "admin:refresh"],
    "aud": "activekg",
    "iss": "https://auth.yourcompany.com",
    "exp": datetime.utcnow() + timedelta(hours=24),
    "iat": datetime.utcnow(),
}

token = jwt.encode(payload, "your-secret-key", algorithm="HS256")
print(token)

# Use in requests:
# curl -H "Authorization: Bearer <token>" http://localhost:8000/nodes/...
```

---

### 2. Rate Limiting (1-2 hours)

**Step 1: Start Redis**

```bash
# Docker
docker run -d --name activekg-redis -p 6379:6379 redis:7-alpine

# Or use managed Redis (AWS ElastiCache, Redis Cloud, etc.)
```

**Step 2: Configure limits**

Edit `activekg/api/rate_limiter.py` (lines 19-31) to adjust per-endpoint limits:

```python
RATE_LIMITS = {
    "search": {"rate": 50, "burst": 100},      # 50 req/s sustained, 100 burst
    "ask": {"rate": 3, "burst": 5},            # 3 req/s (expensive LLM calls)
    "ask_stream": {"rate": 1, "burst": 3},     # 1 req/s streaming
    "admin_refresh": {"rate": 1, "burst": 2},  # 1 req/s admin ops
    "default": {"rate": 100, "burst": 200},    # Other endpoints
}

CONCURRENCY_LIMITS = {
    "ask": 3,          # Max 3 concurrent /ask per tenant
    "ask_stream": 2,   # Max 2 concurrent /ask/stream per tenant
}
```

**Step 3: Add rate limit headers to responses**

Edit `activekg/api/main.py` to expose rate limit info:

```python
from fastapi import Response

@app.post("/ask")
async def ask_question(
    request: AskRequest,
    response: Response,  # ‚Üê Add this
    claims: Optional[JWTClaims] = Depends(get_jwt_claims),
    _rate_limit: None = Depends(...)
):
    # ... existing logic ...

    # Add rate limit headers to response
    if hasattr(request, "rate_limit_info"):
        info = request.rate_limit_info
        response.headers["X-RateLimit-Limit"] = str(info.limit)
        response.headers["X-RateLimit-Remaining"] = str(info.remaining)
        response.headers["X-RateLimit-Reset"] = str(info.reset_at)

    return response_data
```

**Step 4: Test rate limiting**

```bash
# Should succeed (first request)
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "test"}'

# Should fail with 429 after 5 rapid requests
for i in {1..10}; do
  curl -X POST http://localhost:8000/ask \
    -H "Content-Type: application/json" \
    -d '{"question": "test"}' &
done
```

---

## ‚ö†Ô∏è P1: Observability & Documentation

### 3. Reranker Telemetry (1 hour)

**Problem**: Your `/ask` endpoint doesn't expose reranker metadata, making debugging impossible.

**Fix**: Modify `activekg/api/main.py` (lines 929-946):

```python
# Capture rerank scores from hybrid_search
# Option A: Modify hybrid_search to return rerank_score
# Option B: Add separate metadata field

# In hybrid_search (repository.py:416), change:
# return [(node, hybrid_score) for node, hybrid_score, _ in reranked]
# TO:
return [(node, hybrid_score, rerank_score) for node, hybrid_score, rerank_score in reranked]

# Then in /ask endpoint:
results = repo.hybrid_search(...)  # Returns [(node, hybrid_score, rerank_score)]

# Extract top rerank score
top_rerank_logit = results[0][2] if results and len(results[0]) > 2 else None
top_rerank_prob = 1 / (1 + math.exp(-top_rerank_logit)) if top_rerank_logit else None

# Add to metadata
response = {
    "answer": answer,
    "citations": citations,
    "confidence": confidence,
    "metadata": {
        "searched_nodes": len(results),
        "filtered_nodes": len(filtered_results),
        "cited_nodes": len(citations),
        "top_similarity": round(top_similarity, 3),
        "top_similarity_hybrid": round(top_similarity, 3),  # ‚Üê Add
        "top_rerank_logit": round(top_rerank_logit, 3) if top_rerank_logit else None,  # ‚Üê Add
        "top_rerank_prob": round(top_rerank_prob, 3) if top_rerank_prob else None,      # ‚Üê Add
        "rerank_enabled": not skip_rerank,  # ‚Üê Add
        "rerank_candidates": int(os.getenv("HYBRID_RERANKER_CANDIDATES", "20")),  # ‚Üê Add
        "llm_path": llm_path,
        "routing_reason": routing_reason,
        ...
    }
}
```

### 4. Environment Toggles (30 minutes)

**Add to `activekg/api/main.py` (after line 64):**

```python
# Reranker configuration
ASK_USE_RERANKER = os.getenv("ASK_USE_RERANKER", "true").lower() == "true"
RERANK_SKIP_TOPSIM = float(os.getenv("RERANK_SKIP_TOPSIM", "0.80"))
HYBRID_RERANKER_CANDIDATES = int(os.getenv("HYBRID_RERANKER_CANDIDATES", "20"))  # Already exists

# Wire to /ask endpoint (line 758):
use_reranker=ASK_USE_RERANKER and not skip_rerank
```

**Environment variables:**

```bash
# Reranker toggles
ASK_USE_RERANKER=true           # Master switch
RERANK_SKIP_TOPSIM=0.80         # Skip rerank if top hybrid_score ‚â• 0.80
HYBRID_RERANKER_CANDIDATES=20   # Candidate pool size before reranking
```

### 5. Prometheus Metrics for Reranking (1 hour)

**Add to `activekg/common/metrics.py`:**

```python
# Reranker metrics
def increment_rerank_invocations(used: bool, reason: str):
    """Track rerank usage.

    Labels:
    - used: true/false (whether reranking was applied)
    - reason: structured/highconf/smallk/applied
    """
    metrics.increment(f"rerank.invocations.{used}.{reason}")

def track_rerank_latency(latency_ms: float):
    """Track cross-encoder reranking latency."""
    metrics.histogram("rerank.latency_ms", latency_ms)

def increment_ask_route(path: str):
    """Track LLM routing decisions.

    Labels:
    - path: fast/fallback
    """
    metrics.increment(f"ask.routed.{path}")
```

**Wire into `/ask` endpoint:**

```python
# Before hybrid_search
rerank_start = time.time()

results = repo.hybrid_search(
    query_text=request.question,
    query_embedding=query_embedding,
    top_k=20,
    tenant_id=request.tenant_id,
    use_reranker=not skip_rerank
)

# After hybrid_search
if not skip_rerank:
    rerank_latency_ms = (time.time() - rerank_start) * 1000
    metrics.track_rerank_latency(rerank_latency_ms)
    metrics.increment_rerank_invocations(used=True, reason="applied")
else:
    skip_reason = "structured" if intent_type else ("highconf" if top_score >= 0.80 else "smallk")
    metrics.increment_rerank_invocations(used=False, reason=skip_reason)

# Track routing
metrics.increment_ask_route(llm_path)  # "fast" or "fallback"
```

### 6. Documentation (1 hour)

**Create `RERANKER_SEMANTICS.md`:**

```markdown
# Active Graph KG - Reranker Semantics

## Overview

Active Graph KG uses a **dual-score reranking architecture** to balance precision and recall:

1. **Hybrid Score** (BM25 + vector fusion, range [0, 1])
   - Used for: gating, thresholding, top_similarity reporting
   - Formula: `0.7 * cosine_sim + 0.3 * normalized_ts_rank`

2. **Rerank Score** (cross-encoder logit, unbounded)
   - Used for: final ordering only
   - Model: `cross-encoder/ms-marco-MiniLM-L-6-v2`

## When Reranking Skips

Reranking is **automatically skipped** in these cases:

1. **Structured intents**: Queries routed to `list_open_positions()` or `list_performance_issues()`
   - Reason: Intent-based retrieval already precise

2. **High confidence**: Top hybrid_score ‚â• 0.80 (configurable via `RERANK_SKIP_TOPSIM`)
   - Reason: Hybrid fusion already confident, reranking adds latency with minimal gain

3. **Small result sets**: K < 3 candidates
   - Reason: Cross-encoder needs context variety to be effective

## Key Invariants

‚úÖ **DO**: Use `hybrid_score` for thresholds (`ASK_SIM_THRESHOLD`, gating logic)
‚úÖ **DO**: Use `rerank_score` for final ordering
‚ùå **DON'T**: Use `rerank_score` for thresholds (unbounded, not comparable to hybrid_score)
‚ùå **DON'T**: Leak rerank scores to metadata fields named "similarity" (breaks API contract)

## Environment Configuration

```bash
ASK_USE_RERANKER=true           # Master switch
RERANK_SKIP_TOPSIM=0.80         # Skip if top hybrid_score ‚â• this
HYBRID_RERANKER_CANDIDATES=20   # Candidate pool size
```

## Observability

Reranker metadata exposed in `/ask` responses:

```json
{
  "metadata": {
    "top_similarity": 0.712,           // Hybrid score (for thresholding)
    "top_similarity_hybrid": 0.712,    // Same as top_similarity
    "top_rerank_logit": 8.34,          // Cross-encoder raw score
    "top_rerank_prob": 0.9997,         // sigmoid(logit)
    "rerank_enabled": true,            // Whether rerank was used
    "rerank_candidates": 20            // Pool size before reranking
  }
}
```

## Performance

- **Latency**: ~50-100ms for 20 candidates (single-threaded CPU)
- **Accuracy gain**: +5-10% NDCG@10 vs hybrid-only (typical)
- **Skip rate**: 30-40% (structured intents + high-confidence queries)

## References

- Cross-encoder model: https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2
- MS MARCO dataset: https://microsoft.github.io/msmarco/
```

**Update `README.md` (line 365):**

```markdown
## API Endpoints (14 Total)

### Q&A
- `POST /ask` - LLM-powered Q&A with citations (supports hybrid routing + reranking)
- `POST /ask/stream` - Server-sent events streaming for /ask

**Note**: See [RERANKER_SEMANTICS.md](RERANKER_SEMANTICS.md) for details on hybrid scoring and cross-encoder reranking.
```

---

## üìä Database Recommendations

### 7. Migrations Tool (2 hours)

**Install Alembic:**

```bash
pip install alembic==1.13.0
alembic init db/migrations
```

**Configure `db/migrations/env.py`:**

```python
from activekg.graph.models import Base  # If using SQLAlchemy
target_metadata = Base.metadata
```

**Create first migration:**

```bash
# Auto-generate migration from schema
alembic revision --autogenerate -m "initial schema"

# Or create manual migration
alembic revision -m "add_hnsw_index"
```

**Example migration for HNSW index:**

```python
# db/migrations/versions/001_add_hnsw_index.py
def upgrade():
    op.execute("""
        CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_nodes_embedding_hnsw
        ON nodes USING hnsw (embedding vector_cosine_ops)
        WITH (m=16, ef_construction=64);
    """)

def downgrade():
    op.execute("DROP INDEX IF EXISTS idx_nodes_embedding_hnsw;")
```

**Apply migrations:**

```bash
# Upgrade to latest
alembic upgrade head

# Rollback one version
alembic downgrade -1
```

### 8. Connection Pooling with pgBouncer (1 hour)

**Install pgBouncer:**

```bash
# Ubuntu/Debian
sudo apt-get install pgbouncer

# Docker
docker run -d --name pgbouncer \
  -p 6432:6432 \
  -v /path/to/pgbouncer.ini:/etc/pgbouncer/pgbouncer.ini \
  edoburu/pgbouncer
```

**Configure `pgbouncer.ini`:**

```ini
[databases]
activekg = host=localhost port=5432 dbname=activekg

[pgbouncer]
listen_addr = 0.0.0.0
listen_port = 6432
auth_type = md5
auth_file = /etc/pgbouncer/userlist.txt
pool_mode = session
max_client_conn = 1000
default_pool_size = 25
server_lifetime = 3600
server_idle_timeout = 600
```

**Update DSN:**

```bash
# Before (direct Postgres)
ACTIVEKG_DSN=postgresql://activekg:activekg@localhost:5432/activekg

# After (via pgBouncer)
ACTIVEKG_DSN=postgresql://activekg:activekg@localhost:6432/activekg
```

### 9. HNSW Index for Production (30 minutes)

**Add to `enable_vector_index.sql`:**

```sql
-- Option 1: HNSW (better for read-heavy workloads)
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_nodes_embedding_hnsw
ON nodes USING hnsw (embedding vector_cosine_ops)
WITH (m=16, ef_construction=64);

-- Option 2: IVFFLAT (current, better for write-heavy)
-- Already implemented

-- Performance comparison:
-- HNSW: 10-20ms p95 @ 100K nodes (read), slower builds
-- IVFFLAT: 30-50ms p95 @ 100K nodes (read), faster builds
```

**Tune for your workload:**

```sql
-- Read-heavy: use HNSW
SET hnsw.ef_search = 100;  -- Higher = better recall, slower

-- Write-heavy: use IVFFLAT
SET ivfflat.probes = 10;   -- Lower = faster, less accurate
```

### 10. Scheduled VACUUM (15 minutes)

**Add cron job:**

```bash
# /etc/cron.daily/activekg-vacuum
#!/bin/bash
psql $ACTIVEKG_DSN -c "VACUUM (ANALYZE, VERBOSE) nodes;"
psql $ACTIVEKG_DSN -c "VACUUM (ANALYZE, VERBOSE) edges;"
psql $ACTIVEKG_DSN -c "VACUUM (ANALYZE, VERBOSE) events;"
```

---

## üéØ Evaluation Harness Improvements

### 11. Consolidate Results at End of run_all.sh (15 minutes)

**Edit `evaluation/run_all.sh`:**

```bash
#!/bin/bash
set -e

# ... existing test runs ...

# Consolidate results at the end
echo "Consolidating results..."
python evaluation/consolidate_results.py

echo "‚úÖ Evaluation complete. See evaluation/results.json for consolidated report."
```

### 12. Add Representative Test Data (1 hour)

**Create `evaluation/seed_aged_nodes.py`:**

```python
"""Seed nodes with synthetic age/drift for weighted search evaluation."""

import requests
from datetime import datetime, timedelta
import random

API_URL = "http://localhost:8000"

def create_aged_node(age_days: int, drift_score: float, title: str, text: str):
    """Create node with backdated timestamp and synthetic drift."""
    created_at = datetime.utcnow() - timedelta(days=age_days)

    response = requests.post(f"{API_URL}/nodes", json={
        "classes": ["Article"],
        "props": {
            "title": title,
            "text": text,
            "created_at": created_at.isoformat()
        },
        "metadata": {
            "category": "test",
            "age_days": age_days,
            "synthetic_drift": drift_score
        },
        "refresh_policy": {
            "interval": "1d",
            "drift_threshold": 0.1
        }
    })

    node_id = response.json()["id"]

    # Manually set drift_score via SQL (if needed)
    # Or refresh with perturbed embedding

    return node_id

# Seed aged cohorts
for age_days in [0, 7, 14, 30, 60, 90]:
    for i in range(3):
        create_aged_node(
            age_days=age_days,
            drift_score=random.uniform(0.0, 0.3),
            title=f"Article from {age_days} days ago - {i}",
            text=f"Content published {age_days} days ago. Topic: vector databases."
        )

print("‚úÖ Seeded 18 aged nodes for weighted search evaluation.")
```

---

## ‚úÖ Sanity Tests to Keep

**Add to `tests/test_reranker.py`:**

```python
def test_rerank_skip_structured_intent():
    """Verify reranking is skipped for structured intents."""
    response = requests.post(f"{API_URL}/ask", json={
        "question": "What ML engineer positions are open?"
    })

    metadata = response.json()["metadata"]
    assert metadata["intent_detected"] == "open_positions"
    assert metadata["rerank_enabled"] == False, "Should skip rerank for structured intent"

def test_rerank_skip_high_confidence():
    """Verify reranking is skipped for high-confidence queries."""
    response = requests.post(f"{API_URL}/ask", json={
        "question": "exact product title match query"
    })

    metadata = response.json()["metadata"]
    assert metadata["top_similarity"] >= 0.80
    assert metadata["rerank_enabled"] == False, "Should skip rerank for high confidence"

def test_rerank_applied():
    """Verify reranking is applied when appropriate."""
    response = requests.post(f"{API_URL}/ask", json={
        "question": "vague query with multiple candidates"
    })

    metadata = response.json()["metadata"]
    assert metadata["top_similarity"] < 0.80
    assert metadata["rerank_enabled"] == True
    assert metadata["top_rerank_logit"] is not None
    assert -20 <= metadata["top_rerank_logit"] <= 20  # Sanity check

def test_threshold_gating_uses_hybrid_score():
    """Verify threshold decisions use hybrid_score, not rerank_score."""
    # Create low-quality node with high noise
    # Query should be gated by hybrid_score threshold, not rerank
    response = requests.post(f"{API_URL}/ask", json={
        "question": "completely unrelated query"
    })

    metadata = response.json()["metadata"]
    assert metadata["top_similarity"] < 0.25  # Below ASK_SIM_THRESHOLD
    assert response.json()["confidence"] == 0.2  # Bailout response
```

---

## üìã Deployment Checklist

### Pre-Production

- [ ] JWT authentication enabled (`JWT_ENABLED=true`)
- [ ] JWT secret key configured (RS256 public key)
- [ ] Rate limiting enabled (`RATE_LIMIT_ENABLED=true`)
- [ ] Redis deployed and accessible
- [ ] pgBouncer connection pooling configured
- [ ] HNSW or IVFFLAT index created (`enable_vector_index.sql`)
- [ ] RLS policies enabled (`enable_rls_policies.sql`)
- [ ] Scheduled VACUUM configured (daily cron)
- [ ] Prometheus metrics endpoint accessible (`/prometheus`)
- [ ] Grafana dashboards imported
- [ ] Alerting rules configured (high drift, slow search, rate limit breaches)

### Post-Deployment Validation

- [ ] Test JWT with invalid token (should return 401)
- [ ] Test JWT with missing scopes (should return 403)
- [ ] Test rate limiting (rapid requests should return 429)
- [ ] Test tenant isolation (JWT tenant_id enforced in queries)
- [ ] Run evaluation harness (`./evaluation/run_all.sh`)
- [ ] Verify rerank metadata in /ask responses
- [ ] Check Prometheus metrics (rerank invocations, routing decisions)

---

## üìù Quick Commands

```bash
# Install new dependencies
pip install PyJWT[crypto]==2.8.0 redis==5.0.1 alembic==1.13.0

# Start Redis
docker run -d --name activekg-redis -p 6379:6379 redis:7-alpine

# Generate dev JWT
python -c "
import jwt
from datetime import datetime, timedelta
payload = {
    'sub': 'dev_user',
    'tenant_id': 'dev_tenant',
    'scopes': ['admin:refresh'],
    'aud': 'activekg',
    'exp': datetime.utcnow() + timedelta(days=1)
}
print(jwt.encode(payload, 'dev-secret', algorithm='HS256'))
"

# Test with JWT
TOKEN=<paste-token>
curl -H "Authorization: Bearer $TOKEN" http://localhost:8000/nodes

# Test rate limiting
for i in {1..10}; do curl -X POST http://localhost:8000/ask -d '{"question":"test"}' & done

# Create HNSW index
psql $ACTIVEKG_DSN -f enable_vector_index.sql

# Run evaluation
./evaluation/run_all.sh
```

---

## üéØ Success Criteria

After completing this guide:

‚úÖ **Security**: Tenant isolation enforced via JWT (no client-supplied tenant_id)
‚úÖ **Reliability**: Rate limits prevent cost spikes and noisy neighbor problems
‚úÖ **Observability**: Rerank metadata exposed in /ask responses and Prometheus
‚úÖ **Documentation**: Reranker semantics documented for future maintainers
‚úÖ **Production-Ready**: 100% deployment checklist passed

**Estimated Total Effort**: 8-12 hours (P0 + P1 tasks)

---

## üìö Next Steps (Phase 2)

These are **nice-to-haves** but not blocking for production:

1. **Synonym Expansion** (improve recall for domain-specific queries)
2. **E5-large-v2 Embedding Upgrade** (better semantic understanding, 1024 dims)
3. **GET /nodes/{id}/versions** (version history endpoint) ‚úÖ Already implemented!
4. **LISTEN/NOTIFY for events** (push-based UI updates)
5. **WebSocket /ask/stream** (alternative to SSE)
6. **Query expansion with LLM** (e.g., "ML engineer" ‚Üí "machine learning engineer, data scientist")

See [FUTURE_IMPROVEMENTS.md](FUTURE_IMPROVEMENTS.md) for full roadmap.
